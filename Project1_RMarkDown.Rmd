---
title: "Untitled"
author: 'Rene Pineda, '
date: "June 11, 2018"
output:
  pdf_document: default
  html_document: default
---

#MSDS 6371 Project 1

## Setup and Loading packagges

```{r setup, echo=FALSE}
list.of.packages <- c("sqldf", "glmnet", "gfortran", "rgl", "CVST", "igraph", "recipes", "ggplot2", "caret", "forcats", "olsrr", "tidyr", "corrplot", "parallel", "doParallel")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, repos="http://cran.r-project.org")
```

```{r setup, echo=FALSE}

#Load the data
train <- read.csv("train.csv")
test <- read.csv("test.csv")

#Inspect the data
dim(train)
str(train)

library(sqldf) # Used for manipulating the data frames using SQL
library(glmnet) # Used for...
library(caret) # Used for...
library(forcats) # Used for...
library(olsrr) # Used for creating the foward, backward, and stepwise models
library(tidyr) #Used for creating some of the plots
library(ggplot2) #Used for creating some of the plots
library(corrplot) #Used to create the correlation matrix
library(parallel) #Using to assign more cores and allow parallel processing
library(doParallel)#Using to assign more cores and allow parallel processing
```



## Data cleaning and preparation

```{r data preparation, echo=FALSE}


#Going to assign more cores to R and leave one for OS. Not sure if it will help feature selection
#but worth a shot.

cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

fitControl <- trainControl(method = "cv", number = 3, allowParallel = TRUE)


#This shows us what is null
sapply(train, function(x) sum(is.na(x)))

#upon inspecton, the following variables have missing information:
#LotFrontage, Alley, MasVnrType, MasVnrArea, BsmtQual, BstCond, BsmtExposure, BsmtFinType1, BsmtFinType2,
#FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCond, Fence, MiscFeature, PoolQC

#Adding sale price to the test set for combining
test$SalePrice <- 0  

#Join the train and test sets for preprocessing
data <- rbind(train, test)

#Converting values to NULL in the following variables tha will not be used
data$MiscFeature <- NULL # Missing value in 96.4% of observations
data$Alley <- NULL # Missing value in 93.2% of observations
data$PoolQC <- NULL # Missing value in 99.7% of observations

#Variables with values as NA
NAFeatures = names(which(colSums(is.na(data))>0))

#Get the median lot frontage and update where NA
median(train$LotFrontage, na.rm = TRUE)  # This ends up being 69.  Going to update the NA 

data$LotFrontage[is.na(data$LotFrontage)] <-69

#If NA for GarageYrBlt, then set to YearBuilt of house
data$GarageYrBlt[is.na(data$GarageYrBlt)] <-  as.integer(data$YearBuilt)

#Create vectors of Variables with missing observations and variables with zero values
missingObs = c("MSZoning", "MasVnrType", "Utilities", "Exterior1st", "Exterior2nd", "SaleType")
effZero = c("LotFrontage", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF","GarageCars", "GarageArea", "BsmtFullBath", "BsmtHalfBath")

# Get Effectively Absent category by excluding other categories from varsWithNA
effAbsent = NAFeatures[!NAFeatures %in% missingObs]
effAbsent = effAbsent[!effAbsent %in% effZero]
effAbsent = effAbsent[!effAbsent %in% c("Functional")]

# Function for replacing NAs in nominal and ordinal variables
replaceNAfactor = function(data.col, factorString){
  char.col <- as.character(data.col)
  char.col[which(is.na(data.col))] <- factorString
  as.factor(char.col)
}

# Replace NAs with None in Effectively Absent category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% effAbsent){
    data[,i] <- replaceNAfactor(data[,i], "None")}
}

# Replace NAs with MissingObs in Missing Observations category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% missingObs){
    data[,i] <- replaceNAfactor(data[,i], "MissingObs")}
}

# Replace NAs with 0 in Effectively Zero category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% effZero)
    data[is.na(data[,i]),i] <- 0
}

data$Functional <- replaceNAfactor(data$Functional, "Typ")

#Checking that we corrected for NAs
sapply(data, function(x) sum(is.na(x)))

#Resplitting train and test
xtrain <- as.data.frame(sqldf("select * from data where SalePrice <> 0"))
ytrain <- sqldf("select SalePrice from data where SalePrice <> 0")
names(ytrain) <- c("SalePrice")

xtrain$SalePrice <- NULL

xtest <- sqldf("select * from data where SalePrice = 0")

xtest$SalePrice <- NULL
```

## Some exploratory Analysis


```{r Corr Matrix and Scatterplots, echo=FALSE}
#Correlation matrix
#The following variables will be included in the matrix: Lot Frontage, Lot Area, Year Built, Year Remod/Add, 
#Mas Vnr Area, Bsmt Fin SF 1, BsmtFin SF 2, Bsmt Unf SF, Total Bsmt SF, 1st Flr SF, 2nd Flr SF, Low Qual Fin SF,
#Gr Liv Area, Garage Area, Wood Deck Sf, Open Porch SF, Enclosed Porch, 3-Ssn Porch, Screen Porch, Pool Area, 
#Misc Val, Yr Sold, Sale Price

#Choose only these variables:
numericvars <- xtrain[,c(4,5,19,20,26,34,36,37,38,43,44,45,46,62,66,67,68,69,70,71,73,75)]
nonnumericvars <- xtrain[,-c(4,5,19,20,26,34,36,37,38,43,44,45,46,62,66,67,68,69,70,71,73,75)]
corrvar <- cbind(numericvars,ytrain)

#Create the correlation matrix

N <- cor(corrvar, use = "complete.obs")
corrplot(N, method = "number", number.cex = 0.5, tl.cex = 0.7)           

#Create the scatterplots

#Function to create the scatterplots
scatterplots <- cbind(xtrain, ytrain)

makeScatterplots <- function(dataframe,x.variable){
  print(ggplot(data = dataframe) + 
    geom_point(mapping = aes(x = scatterplots[,x.variable], y = SalePrice), color = "dodgerblue3" ) +
    scale_y_continuous(labels = scales::dollar) +
    labs(x = (names(scatterplots[x.variable]))))
  }

#Create the scatterplots you're interested in by changing the variable numbers in the FOR statement
for (variable in c(2,75,25,6,8,14,29)){
  makeScatterplots(scatterplots,variable)
}
```




##Regression Models

So far we've created four regression models
* Initial model with all variables: modelfit1
* LASSO model
* Forward selection model using p-values as criteria: modelfoward
* Backward selection model using p-values as criteria: modelbackward
* Stepwise selection model using p-values as criteria: modelstepwise

```{r Regression models, echo=FALSE}
#Running an initial regression model with all the data
modelfit1 <- lm(ytrain$SalePrice ~ ., data = xtrain[,-1])
summary(modelfit1)
#R^2 is .937
summary(modelfit1)$adj.r.squared



# Testing model interactions from problem 2 analysis
modelfit2 <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition + KitchenQual * Neighborhood, data = xtrain[,-1])

summary(modelfit2)

modelfit3 <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition + KitchenQual * Neighborhood + SaleCondition * Neighborhood , data = xtrain[,-1])

summary(modelfit3)


```


##Outlier Analysis

```{r}
#Remove High Leverage Points and Cooks D and create new train set from  this

cooksd <- cooks.distance(modelfit1)


sample_size <- nrow(xtrain)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels


#Removing outliers with high cooks d
influential <- (as.numeric(names(cooksd)[(cooksd > (4/sample_size))]))

influential <- influential[!is.na(influential)]

xtrain <- as.data.frame(xtrain[-influential,])

ytrain <- as.data.frame(ytrain[-influential,])

names(ytrain) <- c("SalePrice")


```


#Lasso Model


```{r}
`%ni%` <- Negate(`%in%`)

x = model.matrix(ytrain$SalePrice~., data = xtrain[,-1]) 
y = (ytrain$SalePrice)

cv.out <- cv.glmnet(x,y,alpha = 1)
plot(cv.out)
bestlambda <- cv.out$lambda.1se

c<- coef(cv.out, s = bestlambda, extract = TRUE)
inds <- which(c!=0)
variables <- row.names(c)[inds]
variables <- variables[variables %ni% ('Intercept')]
variables

library(MASS)

#Forward selection model
model <- lm(ytrain$SalePrice ~ ., data = xtrain[,-1])  #added [,-1] part so that we remove the id from model
modelforward <- ols_step_forward(model)  #Took out the _p from this and it worked
modelforward
summary(modelforward)

steps <- modelforward$steps

modelforward$adjr[steps]

modelforward$rmse[steps]

modelforward$predictors

plot(modelforward)

#Backward Selection model  #Taking 18 hours to run so far (JM) Corrected code, but taking to long. 
#Code does not work as desired
#modelbackward <- ols_step_backward(model)
#modelbackward

#jm - I usually use the MASS package for feature selection and this worked. 
backward.mass <- stepAIC(model, direction = "backward", trace = FALSE, steps = 100)

summary(backward.mass)


stepwise.mass <- stepAIC(model, direction = "both", trace = FALSE, steps = 500)

summary(stepwise.mass)

#summary(modelbackward)

#steps <- modelbackward$steps

#modelbackward$adjr[steps]

#modelbackward$rmse[steps]

#modelbackward$predictors

#plot(modelbackward)

#Stepwise Selection model
#modelstepwise <- ols_step_both(model)
#modelstepwise
#plot(modelstepwise)

```

##Pending tasks
* Run several models from all the selection processes. - Rene 
* Create table comparing comparing AIC or R^2 from all models, and make decision - Rene
* Enter interaction terms (ex:  GarageYrBuilt * GarageCars * GarageArea ) -- Samira?
* Clean up and prep final doc within the rmarkdown? - Samira? 
* Perform the 2-way ANOVA analysis for the second part of the project assignment  --Rajat
