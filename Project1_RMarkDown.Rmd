---
title: "Project1"
author: "Jonathan Marin, Rajat Chandna, Rene Alvarenga, Samira Zarandioon"
date: "June 11, 2018"
output:
  pdf_document: default
  html_document: default
---



```{r setup, echo=FALSE, include = FALSE}
# install the required packages if needed
list.of.packages <- c("sqldf", "glmnet", "gfortran", "rgl", "CVST", "igraph", "recipes", "ggplot2", "caret", "forcats", "olsrr", "tidyr", "corrplot", "parallel", "doParallel")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, repos="http://cran.r-project.org")
```

```{r echo=FALSE, include = FALSE}
# load the required libraries
library(sqldf) # Used for manipulating the data frames using SQL
library(glmnet) # Used for...
library(caret) # Used for...
library(forcats) # Used for...
library(olsrr) # Used for creating the foward
library(MASS) # Used for backward, and stepwise models
library(tidyr) #Used for creating some of the plots
library(ggplot2) #Used for creating some of the plots
library(corrplot) #Used to create the correlation matrix
library(parallel) #Using to assign more cores and allow parallel processing
library(doParallel) #Using to assign more cores and allow parallel processing
```

```{r echo=FALSE, include = FALSE}

# Set seed for reproducibility
set.seed(0)

#Load the data
train <- read.csv("train.csv")
test <- read.csv("test.csv")

# Generate histogram of Sale Price
hist(train$SalePrice, main = "Historgram of Sale Price", xlab = "Sale Price in US$")

#Inspect the data
dim(train)
str(train)

```

```{r echo=FALSE, include = FALSE}

# Log transform the sales price

# Perform natural logarithm on response variable.
train$SalePrice <- log(train$SalePrice)

# Generate histogram of log of Sale Price
hist(train$SalePrice, main = "Historgram of natural log of Sale Price", xlab = "Natural log of Sale Price in US$")

```



```{r Data Preparation, echo=FALSE, include = FALSE, warning = FALSE}

#This shows us what is null
sapply(train, function(x) sum(is.na(x)))

#upon inspecton, the following variables have missing information:
#LotFrontage, Alley, MasVnrType, MasVnrArea, BsmtQual, BstCond, BsmtExposure, BsmtFinType1, BsmtFinType2,
#FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCond, Fence, MiscFeature, PoolQC

#Adding sale price to the test set for combining (using impossible value of -1 to distinguish between train and test data)
test$SalePrice <- -1  

#Join the train and test sets for preprocessing
data <- rbind(train, test)

#Converting values to NULL in the following variables tha will not be used
data$MiscFeature <- NULL # Missing value in 96.4% of observations
data$Alley <- NULL # Missing value in 93.2% of observations
data$PoolQC <- NULL # Missing value in 99.7% of observations

#Variables with values as NA
NAFeatures = names(which(colSums(is.na(data))>0))

# use median imputation to handle missing LotFrontage data
data$LotFrontage[is.na(data$LotFrontage)] <- median(train$LotFrontage, na.rm = TRUE) #69

#If NA for GarageYrBlt, then set to YearBuilt of house
data$GarageYrBlt[is.na(data$GarageYrBlt)] <-  as.integer(data$YearBuilt)

#Create vectors of Variables with missing observations and variables with zero values
missingObs = c("MSZoning", "MasVnrType", "Utilities", "Exterior1st", "Exterior2nd", "SaleType")
effZero = c("LotFrontage", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF","GarageCars", "GarageArea", "BsmtFullBath", "BsmtHalfBath")

# Get Effectively Absent category by excluding other categories from varsWithNA
effAbsent = NAFeatures[!NAFeatures %in% missingObs]
effAbsent = effAbsent[!effAbsent %in% effZero]
effAbsent = effAbsent[!effAbsent %in% c("Functional")]

# Function for replacing NAs in nominal and ordinal variables
replaceNAfactor = function(data.col, factorString){
  char.col <- as.character(data.col)
  char.col[which(is.na(data.col))] <- factorString
  as.factor(char.col)
}

# Replace NAs with None in Effectively Absent category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% effAbsent){
    data[,i] <- replaceNAfactor(data[,i], "None")}
}

# Replace NAs with MissingObs in Missing Observations category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% missingObs){
    data[,i] <- replaceNAfactor(data[,i], "MissingObs")}
}

# Replace NAs with 0 in Effectively Zero category
for (i in 1:ncol(data)){
  if(names(data[i]) %in% effZero)
    data[is.na(data[,i]),i] <- 0
}

data$Functional <- replaceNAfactor(data$Functional, "Typ")

#Checking that we corrected for NAs
sapply(data, function(x) sum(is.na(x)))

#Resplitting train and test
xtrain <- as.data.frame(sqldf("select * from data where SalePrice <> -1"))
ytrain <- sqldf("select SalePrice from data where SalePrice <> -1")
names(ytrain) <- c("SalePrice")

xtrain$SalePrice <- NULL

xtest <- sqldf("select * from data where SalePrice = -1")

xtest$SalePrice <- NULL
```



```{r Corr Matrix and Scatterplots, echo=FALSE, include = FALSE}
#Create some histograms

par(mfrow=c(2,2))
hist(train$SalePrice, main = "Historgram of natural log of Sale Price", xlab = "Natural log of Sale Price in US$")
hist(train$GrLivArea, main = "Histogram of GrLivArea", xlab = "Area in Square Feet")
hist(train$YearBuilt, main = "Histogram of Year Built", xlab = "Year in which the House was built")
hist(train$BedroomAbvGr, main = "Histogram of Bedrroms", xlab = "Number of Bedrooms")
dev.off()

#Correlation matrix
#The following variables will be included in the matrix: Lot Frontage, Lot Area, Year Built, Year Remod/Add, 
#Mas Vnr Area, Bsmt Fin SF 1, BsmtFin SF 2, Bsmt Unf SF, Total Bsmt SF, 1st Flr SF, 2nd Flr SF, Low Qual Fin SF,
#Gr Liv Area, Garage Area, Wood Deck Sf, Open Porch SF, Enclosed Porch, 3-Ssn Porch, Screen Porch, Pool Area, 
#Misc Val, Yr Sold, Sale Price

#Choose only these variables:
numericvars <- xtrain[,c(4,5,19,20,26,34,36,37,38,43,44,45,46,62,66,67,68,69,70,71,73,75)]
nonnumericvars <- xtrain[,-c(4,5,19,20,26,34,36,37,38,43,44,45,46,62,66,67,68,69,70,71,73,75)]
corrvar <- cbind(numericvars,ytrain)

#Create the correlation matrix

N <- cor(corrvar, use = "complete.obs")
corrplot(N, method = "number", number.cex = 0.5, tl.cex = 0.7)          

#Create the scatterplots
#Numeric variables:
p1 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,3], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[3])))
p2 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,4], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[4])))
p3 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,9], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[9])))
p4 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,10], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[10])))
p5 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,13], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[13])))
p6 <- ggplot(data = corrvar) + 
  geom_point(mapping = aes(x = corrvar[,14], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(corrvar[14])))
gridExtra::grid.arrange(p1, p2,p3, p4,p5, p6, nrow = 2)

#Nonnumeric variables
nonnumericvars$SalePrice <- corrvar$SalePrice
p7 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,10], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[10])))
p8 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,13], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[13])))
p9 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,14], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[14])))
p10 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,15], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[15])))
p11 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,22], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[22])))
p12 <- ggplot(data = nonnumericvars) + 
  geom_point(mapping = aes(x = nonnumericvars[,40], y = SalePrice), color = "dodgerblue3" ) +
  labs(x = (names(nonnumericvars[40])))
gridExtra::grid.arrange(p7, p8,p9, p10,p11, p12, nrow = 2)
```

##Regression Models

So far we've created four regression models
* Initial model with all variables: modelfit1
* LASSO model
* Forward selection model using p-values as criteria: modelfoward
* Backward selection model using p-values as criteria: modelbackward
* Stepwise selection model using p-values as criteria: modelstepwise
=======

```{r Regression models, echo=FALSE, include = FALSE, warning= FALSE}
#Running an initial regression model with all the data
modelfit_all_fields <- lm(ytrain$SalePrice ~ ., data = xtrain[,-1])
plot(modelfit_all_fields)
#Adjusted R-squared:  0.9337166
print("modelfit_all_fields: ")
summary(modelfit_all_fields)$adj.r.squared

# Testing model interactions from problem 2 analysis
modelfit_without_interactions <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition, data = xtrain[,-1])

#Adjusted R-squared:  0.9337166
print("modelfit_without_interactions: ")
summary(modelfit_without_interactions)$adj.r.squared

modelfit_with_interactions    <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition +
                  # Iteraction terms
                  KitchenQual * Neighborhood +
                  SaleCondition * Neighborhood +
                  OverallCond * OverallQual +
                  GarageYrBlt * GarageCars * GarageArea,
data = xtrain[,-1])

# Adjusted R-squared:  0.9469788
print("modelfit_with_interactions: ")
summary(modelfit_with_interactions)$adj.r.squared
```



```{r, echo = FALSE, include = FALSE}
#Remove High Leverage Points and Cooks D and create new train set from  this

cooksd <- cooks.distance(modelfit_all_fields)


sample_size <- nrow(xtrain)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels


#Removing outliers with high cooks d
influential <- (as.numeric(names(cooksd)[(cooksd > (4/sample_size))]))

influential <- influential[!is.na(influential)]

xtrain <- as.data.frame(xtrain[-influential,])

ytrain <- as.data.frame(ytrain[-influential,])

names(ytrain) <- c("SalePrice")


```


```{r Regression models2, echo=FALSE, include = FALSE}
# retraining the models after removing the influential data points (imporoves the adjusted R^2)

#Running an initial regression model with all the data
modelfit_all_fields_no_influential <- lm(ytrain$SalePrice ~ ., data = xtrain[,-1])
#Adjusted R-squared:  increased from 0.9337166 to 0.968239
print("modelfit_all_fields_no_influential: ")
summary(modelfit_all_fields_no_influential)$adj.r.squared

# Testing model interactions from problem 2 analysis
modelfit_without_interactions_no_influential <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition, data = xtrain[,-1])

#Adjusted R-squared:  increased from  0.9337166 to 0.968239
print("modelfit_without_interactions: ")
summary(modelfit_without_interactions_no_influential)$adj.r.squared

modelfit_with_interactions_no_influential    <- lm(ytrain$SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + xtrain$X1stFlrSF + xtrain$X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + xtrain$X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition +
                  # Iteraction terms
                  KitchenQual * Neighborhood +
                  SaleCondition * Neighborhood +
                  OverallCond * OverallQual +
                  GarageYrBlt * GarageCars * GarageArea,
data = xtrain[,-1])

# Adjusted R-squared:  increased from 0.9469788 to 0.9706955
print("modelfit_with_interactions_no_influential: ")
summary(modelfit_with_interactions_no_influential)$adj.r.squared

```



```{r, echo = FALSE, include = FALSE}
train <- cbind(xtrain, ytrain)
trainControl = trainControl(method = "cv", number = 10, verboseIter = FALSE)

model_all_fields = train(SalePrice ~ ., 
              data = train,
              method = "lm",
              trControl = trainControl)

model_without_interactions = train(SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + X1stFlrSF + X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition,
              data = train,
              method = "lm",
              trControl = trainControl)

model_with_interactions = train(SalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street +  LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + X1stFlrSF + X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea +  Fence +  MiscVal + MoSold + YrSold + SaleType + SaleCondition +
                  # Iteraction terms
                  KitchenQual * Neighborhood +
                  SaleCondition * Neighborhood,
              data = train,
              method = "lm",
              trControl = trainControl)

# auto feature selection

model_forward_selection = train(SalePrice ~ ., 
              data = train,
              method = "leapForward",
              trControl = trainControl)

model_backward_selection = train(SalePrice ~ ., 
              data = train,
              method = "leapBackward",
              trControl = trainControl)

model_stepwise_selection = train(SalePrice ~ ., 
              data = train,
              method = "leapSeq",
              trControl = trainControl)


```



```{r, echo = FALSE, include = FALSE}
`%ni%` <- Negate(`%in%`)

x = model.matrix(ytrain$SalePrice~., data = xtrain[,-1]) 
y = (ytrain$SalePrice)

cv.out <- cv.glmnet(x,y,alpha = 1)
plot(cv.out)
bestlambda <- cv.out$lambda.1se

c<- coef(cv.out, s = bestlambda, extract = TRUE)
inds <- which(c!=0)
variables <- row.names(c)[inds]
variables <- variables[variables %ni% ('Intercept')]
variables

library(MASS)

#Forward selection model  #JM, below code is giving me errors: Could not find function ols_step_forward_p
#model <- lm(ytrain$SalePrice ~ ., data = xtrain[,-1])  #added [,-1] part so that we remove the id from model
#modelforward <- tryCatch({
#    ols_step_forward(model)
#}, warning = function(w) {
#    ols_step_forward_p(model)
#}, error = function(e) {
#    ols_step_forward_p(model)
#})

#modelforward
#summary(modelforward)

#steps <- modelforward$steps

#modelforward$adjr[steps]

#modelforward$rmse[steps]

#modelforward$predictors

#plot(modelforward)

forward.mass <- stepAIC(modelfit_with_interactions, direction = "forward", trace= FALSE, steps = 100)

summary(forward.mass)

#Backward Selection model  #Taking 18 hours to run so far (JM) Corrected code, but taking to long. 
#Code does not work as desired
#modelbackward <- ols_step_backward(model)
#modelbackward

#jm - I usually use the MASS package for feature selection and this worked. 
backward.mass <- stepAIC(modelfit_with_interactions, direction = "backward", trace = FALSE, steps = 100)

summary(backward.mass)


stepwise.mass <- stepAIC(modelfit_with_interactions, direction = "both", trace = FALSE, steps = 500)

summary(stepwise.mass)

#summary(modelbackward)

#steps <- modelbackward$steps

#modelbackward$adjr[steps]

#modelbackward$rmse[steps]

#modelbackward$predictors

#plot(modelbackward)

#Stepwise Selection model
#modelstepwise <- ols_step_both(model)
#modelstepwise
#plot(modelstepwise)


models_list = list(model_all_fields = model_all_fields,
                  model_without_interactions = model_without_interactions,
                  model_with_interactions = model_with_interactions,
                  model_forward_selection = model_forward_selection,
                  model_backward_selection = model_backward_selection,
                  model_stepwise_selection = model_stepwise_selection,
                  forward.mass  = forward.mass,
                  backward.mass = backward.mass,
                  stepwise.mass = stepwise.mass)
resamples = resamples(models_list)
summary(resamples)
```


#MSDS 6371 Project 1

## Setup and Loading packagges



## Data cleaning and preparation


## Some exploratory Analysis


##Regression Models


So far we've created four regression models
* Initial model with all variables: modelfit1
* LASSO model
* Forward selection model using p-values as criteria: modelfoward
* Backward selection model using p-values as criteria: modelbackward
* Stepwise selection model using p-values as criteria: modelstepwise


##Outlier Analysis



#Lasso Model

```{r}
options(scipen=999)

bwplot(resamples, metric = "RMSE")
bwplot(resamples, metric = "Rsquared")
bwplot(resamples, metric = "MAE")
```

##Pending tasks
* Run several models from all the selection processes. - Rene 
* Create table comparing comparing AIC or R^2 from all models, and make decision - Rene
* Enter interaction terms (ex:  GarageYrBuilt * GarageCars * GarageArea ) -- Samira (DONE!)
** I added the following interaction terms, which improved adjusted $R^2$ from 0.9179 to 0.9313
*** KitchenQual * Neighborhood
*** SaleCondition * Neighborhood
*** OverallCond * OverallQual
*** GarageYrBlt * GarageCars * GarageArea
** (Samira) Re-trained the linear models after removing the influenctial datapoints and it increased the adjusted R-squared for the model with interactions form 0.9313 to 0.9611. This means adding the three interaction terms along with removing influential points improves the adjusted R-squared from 0.9179 to 0.9611.
* (Samira): Added logic for model performance comparision between different feature selection strategies.
* Clean up and prep final doc within the rmarkdown? - Samira? 
* Perform the 2-way ANOVA analysis for the second part of the project assignment  --Rajat
